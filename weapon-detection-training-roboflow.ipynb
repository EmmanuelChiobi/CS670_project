{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# Weapon Detection System Using YOLOv8\n",
    "## Real-Time Weapon Detection with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f7c76-f015-4b2e-84db-b2f94e8eec84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:44.610526Z",
     "iopub.status.busy": "2025-11-18T16:08:44.610287Z",
     "iopub.status.idle": "2025-11-18T16:08:44.617221Z",
     "shell.execute_reply": "2025-11-18T16:08:44.616028Z",
     "shell.execute_reply.started": "2025-11-18T16:08:44.610498Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -U \"numpy<2\" ultralytics opencv-python pillow matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:44.618867Z",
     "iopub.status.busy": "2025-11-18T16:08:44.618603Z",
     "iopub.status.idle": "2025-11-18T16:08:46.842380Z",
     "shell.execute_reply": "2025-11-18T16:08:46.841556Z",
     "shell.execute_reply.started": "2025-11-18T16:08:44.618842Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-imports",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-yaml",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:46.843565Z",
     "iopub.status.busy": "2025-11-18T16:08:46.843233Z",
     "iopub.status.idle": "2025-11-18T16:08:46.849875Z",
     "shell.execute_reply": "2025-11-18T16:08:46.848852Z",
     "shell.execute_reply.started": "2025-11-18T16:08:46.843546Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_config = \"\"\"\n",
    "path: /kaggle/input/weapon-detecttion-dataset-roboflow\n",
    "train: train/images\n",
    "val: valid/images\n",
    "\n",
    "nc: 5\n",
    "names: ['Grenade', 'Knife', 'Missile', 'Pistol', 'Rifle']\n",
    "\"\"\"\n",
    "\n",
    "with open('weapon_data.yaml', 'w') as f:\n",
    "    f.write(dataset_config)\n",
    "\n",
    "print(\"Dataset configuration created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "class-names",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:46.851259Z",
     "iopub.status.busy": "2025-11-18T16:08:46.850865Z",
     "iopub.status.idle": "2025-11-18T16:08:46.887559Z",
     "shell.execute_reply": "2025-11-18T16:08:46.886704Z",
     "shell.execute_reply.started": "2025-11-18T16:08:46.851233Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['Grenade', 'Knife', 'Missile', 'Pistol', 'Rifle']\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Total Classes: {num_classes}\")\n",
    "print(f\"Class Names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Model Training with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:46.889932Z",
     "iopub.status.busy": "2025-11-18T16:08:46.889671Z",
     "iopub.status.idle": "2025-11-18T16:08:47.287792Z",
     "shell.execute_reply": "2025-11-18T16:08:47.287140Z",
     "shell.execute_reply.started": "2025-11-18T16:08:46.889878Z"
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(\"YOLOv8 Nano model loaded with COCO pre-trained weights\")\n",
    "print(\"Transfer learning: Fine-tuning entire model for weapon detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T16:08:47.288804Z",
     "iopub.status.busy": "2025-11-18T16:08:47.288619Z",
     "iopub.status.idle": "2025-11-18T17:25:35.390916Z",
     "shell.execute_reply": "2025-11-18T17:25:35.390124Z",
     "shell.execute_reply.started": "2025-11-18T16:08:47.288789Z"
    }
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8n.pt data='/kaggle/working/weapon_data.yaml' epochs=50 imgsz=640"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Training Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-results",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:25:35.392364Z",
     "iopub.status.busy": "2025-11-18T17:25:35.392064Z",
     "iopub.status.idle": "2025-11-18T17:25:35.998485Z",
     "shell.execute_reply": "2025-11-18T17:25:35.997666Z",
     "shell.execute_reply.started": "2025-11-18T17:25:35.392331Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('runs/detect/train')\n",
    "\n",
    "training_results = Image.open(results_path / 'results.png')\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.imshow(training_results)\n",
    "plt.axis('off')\n",
    "plt.title('Training Metrics Over Epochs', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-confusion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:25:36.000009Z",
     "iopub.status.busy": "2025-11-18T17:25:35.999358Z",
     "iopub.status.idle": "2025-11-18T17:25:36.834211Z",
     "shell.execute_reply": "2025-11-18T17:25:36.833457Z",
     "shell.execute_reply.started": "2025-11-18T17:25:35.999985Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_matrix = Image.open(results_path / 'confusion_matrix.png')\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(confusion_matrix)\n",
    "plt.axis('off')\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-best",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:25:36.835330Z",
     "iopub.status.busy": "2025-11-18T17:25:36.835036Z",
     "iopub.status.idle": "2025-11-18T17:25:36.875383Z",
     "shell.execute_reply": "2025-11-18T17:25:36.874581Z",
     "shell.execute_reply.started": "2025-11-18T17:25:36.835310Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model = YOLO(results_path / 'weights/best.pt')\n",
    "\n",
    "print(\"Best model loaded for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:25:36.876563Z",
     "iopub.status.busy": "2025-11-18T17:25:36.876231Z",
     "iopub.status.idle": "2025-11-18T17:25:57.014692Z",
     "shell.execute_reply": "2025-11-18T17:25:57.013741Z",
     "shell.execute_reply.started": "2025-11-18T17:25:36.876525Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = trained_model.val(data='weapon_data.yaml')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-class",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:44:41.664749Z",
     "iopub.status.busy": "2025-11-18T17:44:41.664149Z",
     "iopub.status.idle": "2025-11-18T17:44:41.669217Z",
     "shell.execute_reply": "2025-11-18T17:44:41.668451Z",
     "shell.execute_reply.started": "2025-11-18T17:44:41.664729Z"
    }
   },
   "outputs": [],
   "source": [
    "  available_classes = len(metrics.box.p)\n",
    "  per_class_metrics = pd.DataFrame({\n",
    "      'Class': class_names[:available_classes],\n",
    "      'Precision': metrics.box.p,\n",
    "      'Recall': metrics.box.r,\n",
    "      'mAP50': metrics.box.ap50,\n",
    "      'mAP50-95': metrics.box.ap\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-metrics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:44:42.071689Z",
     "iopub.status.busy": "2025-11-18T17:44:42.071004Z",
     "iopub.status.idle": "2025-11-18T17:44:42.593375Z",
     "shell.execute_reply": "2025-11-18T17:44:42.592682Z",
     "shell.execute_reply.started": "2025-11-18T17:44:42.071663Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "per_class_metrics.plot(x='Class', y='Precision', kind='bar', ax=axes[0,0], color='steelblue', legend=False)\n",
    "axes[0,0].set_title('Precision by Class', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Precision')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "per_class_metrics.plot(x='Class', y='Recall', kind='bar', ax=axes[0,1], color='coral', legend=False)\n",
    "axes[0,1].set_title('Recall by Class', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_ylabel('Recall')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "per_class_metrics.plot(x='Class', y='mAP50', kind='bar', ax=axes[1,0], color='green', legend=False)\n",
    "axes[1,0].set_title('mAP50 by Class', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_ylabel('mAP50')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "per_class_metrics.plot(x='Class', y='mAP50-95', kind='bar', ax=axes[1,1], color='purple', legend=False)\n",
    "axes[1,1].set_title('mAP50-95 by Class', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_ylabel('mAP50-95')\n",
    "axes[1,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Prediction on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-images",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:45:24.799506Z",
     "iopub.status.busy": "2025-11-18T17:45:24.799223Z",
     "iopub.status.idle": "2025-11-18T17:45:24.989973Z",
     "shell.execute_reply": "2025-11-18T17:45:24.989253Z",
     "shell.execute_reply.started": "2025-11-18T17:45:24.799486Z"
    }
   },
   "outputs": [],
   "source": [
    "test_images_path = Path('/kaggle/input/weapon-detecttion-dataset-roboflow/test/images')\n",
    "test_images = list(test_images_path.glob('*.jpg')) + list(test_images_path.glob('*.jpeg')) + list(test_images_path.glob('*.png'))\n",
    "\n",
    "print(f\"Found {len(test_images)} test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-function",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:45:35.040495Z",
     "iopub.status.busy": "2025-11-18T17:45:35.040216Z",
     "iopub.status.idle": "2025-11-18T17:45:35.047117Z",
     "shell.execute_reply": "2025-11-18T17:45:35.046336Z",
     "shell.execute_reply.started": "2025-11-18T17:45:35.040471Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_and_visualize(image_path, model, conf_threshold=0.25):\n",
    "    results = model.predict(source=image_path, conf=conf_threshold, save=False)\n",
    "    \n",
    "    img = cv2.imread(str(image_path))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls = int(box.cls[0])\n",
    "            label = f\"{class_names[cls]} {conf:.2f}\"\n",
    "            \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Detection: {image_path.name}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-tests",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:47:19.370749Z",
     "iopub.status.busy": "2025-11-18T17:47:19.369954Z",
     "iopub.status.idle": "2025-11-18T17:47:28.964488Z",
     "shell.execute_reply": "2025-11-18T17:47:28.963692Z",
     "shell.execute_reply.started": "2025-11-18T17:47:19.370719Z"
    }
   },
   "outputs": [],
   "source": [
    "for test_img in test_images[120:150]:\n",
    "    prediction_results = predict_and_visualize(test_img, trained_model, conf_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Batch Prediction and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-predict",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:06.653806Z",
     "iopub.status.busy": "2025-11-18T17:48:06.653213Z",
     "iopub.status.idle": "2025-11-18T17:48:13.810369Z",
     "shell.execute_reply": "2025-11-18T17:48:13.809559Z",
     "shell.execute_reply.started": "2025-11-18T17:48:06.653777Z"
    }
   },
   "outputs": [],
   "source": [
    "all_detections = []\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = trained_model.predict(source=img_path, conf=0.25, save=False, verbose=False)\n",
    "    \n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            all_detections.append({\n",
    "                'image': img_path.name,\n",
    "                'class': class_names[int(box.cls[0])],\n",
    "                'confidence': float(box.conf[0]),\n",
    "                'bbox': box.xyxy[0].tolist()\n",
    "            })\n",
    "\n",
    "detections_df = pd.DataFrame(all_detections)\n",
    "print(f\"\\nTotal detections: {len(detections_df)}\")\n",
    "print(f\"\\nDetections by class:\")\n",
    "print(detections_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-stats",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:13.811787Z",
     "iopub.status.busy": "2025-11-18T17:48:13.811281Z",
     "iopub.status.idle": "2025-11-18T17:48:14.085543Z",
     "shell.execute_reply": "2025-11-18T17:48:14.084949Z",
     "shell.execute_reply.started": "2025-11-18T17:48:13.811766Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(detections_df) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    detections_df['class'].value_counts().plot(kind='bar', ax=axes[0], color='teal')\n",
    "    axes[0].set_title('Detections by Weapon Class', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Weapon Type')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    axes[1].hist(detections_df['confidence'], bins=20, color='orange', edgecolor='black')\n",
    "    axes[1].set_title('Confidence Score Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Confidence')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Video Prediction for Real-Time Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "video-function",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:14.087378Z",
     "iopub.status.busy": "2025-11-18T17:48:14.087129Z",
     "iopub.status.idle": "2025-11-18T17:48:14.094614Z",
     "shell.execute_reply": "2025-11-18T17:48:14.093936Z",
     "shell.execute_reply.started": "2025-11-18T17:48:14.087359Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_video(video_path, model, output_path='output_video.mp4', conf_threshold=0.3):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    detection_count = 0\n",
    "    \n",
    "    print(f\"Processing video: {total_frames} frames at {fps} FPS\")\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model.predict(source=frame, conf=conf_threshold, save=False, verbose=False)\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                cls = int(box.cls[0])\n",
    "                label = f\"{class_names[cls]} {conf:.2f}\"\n",
    "                \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "                detection_count += 1\n",
    "        \n",
    "        out.write(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames\")\n",
    "    \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"\\nVideo processing complete!\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total detections: {detection_count}\")\n",
    "    print(f\"Output saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-video",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:14.095562Z",
     "iopub.status.busy": "2025-11-18T17:48:14.095345Z",
     "iopub.status.idle": "2025-11-18T17:48:14.115464Z",
     "shell.execute_reply": "2025-11-18T17:48:14.114939Z",
     "shell.execute_reply.started": "2025-11-18T17:48:14.095539Z"
    }
   },
   "outputs": [],
   "source": [
    "video_path = 'test_video.mp4'\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    predict_video(video_path, trained_model, output_path='weapon_detection_output.mp4', conf_threshold=0.3)\n",
    "else:\n",
    "    print(f\"Video file not found: {video_path}\")\n",
    "    print(\"Place your test video in the project directory and update the path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Real-Time Webcam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "webcam-function",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-18T17:25:57.072331Z",
     "iopub.status.idle": "2025-11-18T17:25:57.072578Z",
     "shell.execute_reply": "2025-11-18T17:25:57.072481Z",
     "shell.execute_reply.started": "2025-11-18T17:25:57.072471Z"
    }
   },
   "outputs": [],
   "source": [
    "def realtime_webcam_detection(model, conf_threshold=0.3):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    print(\"Starting webcam detection...\")\n",
    "    print(\"Press 'q' to quit\")\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        results = model.predict(source=frame, conf=conf_threshold, save=False, verbose=False)\n",
    "        \n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            for box in boxes:\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                conf = float(box.conf[0])\n",
    "                cls = int(box.cls[0])\n",
    "                label = f\"{class_names[cls]} {conf:.2f}\"\n",
    "                \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Weapon Detection - Press Q to Quit', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Webcam detection stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-webcam",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-18T17:25:57.073499Z",
     "iopub.status.idle": "2025-11-18T17:25:57.073718Z",
     "shell.execute_reply": "2025-11-18T17:25:57.073625Z",
     "shell.execute_reply.started": "2025-11-18T17:25:57.073615Z"
    }
   },
   "outputs": [],
   "source": [
    "realtime_webcam_detection(trained_model, conf_threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": [
    "## 10. Model Export for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-onnx",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:14.116351Z",
     "iopub.status.busy": "2025-11-18T17:48:14.116141Z",
     "iopub.status.idle": "2025-11-18T17:48:19.955749Z",
     "shell.execute_reply": "2025-11-18T17:48:19.955180Z",
     "shell.execute_reply.started": "2025-11-18T17:48:14.116327Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_model.export(format='onnx')\n",
    "print(\"Model exported to ONNX format for deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-summary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T17:48:19.957443Z",
     "iopub.status.busy": "2025-11-18T17:48:19.957115Z",
     "iopub.status.idle": "2025-11-18T17:48:19.962879Z",
     "shell.execute_reply": "2025-11-18T17:48:19.962212Z",
     "shell.execute_reply.started": "2025-11-18T17:48:19.957423Z"
    }
   },
   "outputs": [],
   "source": [
    "model_info = {\n",
    "    'Model': 'YOLOv8n',\n",
    "    'Classes': num_classes,\n",
    "    'Class Names': ', '.join(class_names),\n",
    "    'Transfer Learning': 'COCO pre-trained weights',\n",
    "    'Fine-tuning': 'Full model (unfrozen)',\n",
    "    'Image Size': '640x640',\n",
    "    'Epochs': 50,\n",
    "    'Batch Size': 16,\n",
    "    'Optimizer': 'Adam',\n",
    "    'Best Weights': str(results_path / 'weights/best.pt')\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for key, value in model_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f98d3-db44-487e-bab7-9b8e59342fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8764969,
     "sourceId": 13771706,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
